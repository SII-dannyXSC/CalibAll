from PIL import Image
import debugpy
import numpy as np
import os

from caliball.dataset.lerobot_dataset import LeRobotDataset
# debugpy.listen(("0.0.0.0", 10092))
# print("ğŸ” Waiting for VSCode attach on 0.0.0.0:10092 ...")
# debugpy.wait_for_client()

# dataset = DroidDataset("/cpfs02/user/xiesicheng.xsc/CalibAll/data",split="train[:10]")
dataset = LeRobotDataset("/cpfs01/user/wenji.zj/dataspace/Data4QwenVLA/RoboMIND_lerobot_v2.1/benchmark1_1_compressed/franka_3rgb/put_the_red_apple_in_the_bowl")

extrinsic = np.array([[ 0.5394, -0.8300, -0.1421, -0.4130],
        [-0.5207, -0.1961, -0.8309,  0.6093],
        [ 0.6618,  0.5222, -0.5379,  0.7001],
        [ 0.0000,  0.0000,  0.0000,  1.0000]])

K = np.array([[572.993 ,  0.     , 320.   ],
              [  0.     , 572.993, 240.   ],        
              [  0.     ,  0.     , 1.   ]])

cnt = 0
for data in dataset:
    video = data["video"]    # T H W C
    joint_angles = data["states"]  # T 6
    eef_pose = data['actions']

    length = len(video)
    
    # å°†æœ«ç«¯æ‰§è¡Œå™¨ï¼ˆeef_poseï¼‰çš„3Dä½ç½®é€šè¿‡extrinsicå’ŒKæŠ•å½±åˆ°2Då›¾åƒä¸Šï¼Œå¹¶æ˜¾ç¤ºåœ¨è§†é¢‘å¸§ä¸Š

    import cv2

    def project_point(point_3d, extrinsic, K):
        """
        å°†ä¸–ç•Œåæ ‡3dç‚¹æŠ•å½±åˆ°åƒç´ åæ ‡ç‚¹
        :param point_3d: np.array([3,])
        :param extrinsic: [4,4]
        :param K: å†…å‚ [3,3]
        :return: (u, v)
        """
        # å°†ç‚¹æ‰©å±•ä¸ºé½æ¬¡åæ ‡
        pt_w = np.append(point_3d, 1)      # shape (4,)
        pt_c = extrinsic @ pt_w            # ç›¸æœºåæ ‡ç³»
        pt_c = pt_c[:3]                    # shape (3,)
        if pt_c[2] == 0:
            pt_c[2] = 1e-5
        px = K @ pt_c
        u = px[0] / px[2]
        v = px[1] / px[2]
        return int(round(u)), int(round(v))


    vis_video = video.copy()
    height, width = vis_video[0].shape[:2]
    output_dir = "/cpfs02/user/xiesicheng.xsc/CalibAll/visualized_videos"
    os.makedirs(output_dir, exist_ok=True)
    out_path = os.path.join(output_dir,f"test_{cnt}.mp4")

    # ä¿å­˜æœ«ç«¯æ‰§è¡Œå™¨ä½ç½®åˆ°ä¸€ä¸ªlist
    eef_pos_list = []
    if eef_pose is not None and len(eef_pose.shape) > 1 and eef_pose.shape[1] >= 3:
        for idx in range(len(vis_video)):
            eef_pos = eef_pose[idx][:3]   # x, y, z (ä¸–ç•Œåæ ‡)
            eef_pos_list.append(eef_pos)

        # è®¡ç®—æ¯ä¸ªæ—¶åˆ»çš„é€Ÿåº¦æ–¹å‘
        eef_pos_arr = np.array(eef_pos_list)  # (T, 3)
        velocities = np.diff(eef_pos_arr, axis=0)  # (T-1, 3)
        directions = np.sign(velocities) # æ–¹å‘ï¼ˆæ¯ä¸ªåˆ†é‡ï¼‰
        # ä½ ä¹Ÿå¯ä»¥å–æ•´ä½“æ–¹å‘ï¼Œä¾‹å¦‚å•ä½å‘é‡ï¼š
        norm = np.linalg.norm(velocities, axis=1, keepdims=True)
        velocity_dirs = velocities / (norm + 1e-8)
        # velocity_dirsç°åœ¨æ˜¯(T-1, 3)ï¼Œè¡¨ç¤ºæ¯å¸§çš„é€Ÿåº¦æ–¹å‘ï¼ˆå•ä½å‘é‡ï¼‰

    # æŠŠé€Ÿåº¦æ–¹å‘ï¼ˆx,y,zçš„æ­£è´Ÿï¼‰å†™åœ¨æ¯ä¸€å¸§ä¸Š

    # é‡æ–°æ‰“å¼€è§†é¢‘å†™å™¨
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    fps = 15  # ä½ å¯ä»¥æ ¹æ®æ•°æ®å®é™…å¸§ç‡ä¿®æ”¹
    writer = cv2.VideoWriter(out_path, fourcc, fps, (width, height))

    for idx in range(len(vis_video)):
        frame = vis_video[idx]
        frame_bgr = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR) if frame.shape[2] == 3 else frame

        # å¯è§†åŒ–eefä½ç½®
        if eef_pose is not None and len(eef_pose.shape) > 1 and eef_pose.shape[1] >= 3:
            eef_pos = eef_pose[idx][:3]
            u, v = project_point(eef_pos, extrinsic, K)
            cv2.circle(frame_bgr, (u, v), 8, (0,0,255), -1)

            # é€Ÿåº¦æ–¹å‘å¯è§†åŒ–ï¼ˆç¬¬0å¸§æ— velocityï¼‰
            if idx > 0:
                vdir = velocity_dirs[idx-1]
                # æŒ‰è¦æ±‚æ˜ å°„æ–¹å‘
                x_dir = "forward" if vdir[0] > 0 else "backward"
                y_dir = "left" if vdir[1] > 0 else "right"
                z_dir = "upward" if vdir[2] > 0 else "downward"
                txt = f"x:{x_dir} y:{y_dir} z:{z_dir}"
                # å†™åœ¨å›¾åƒå·¦ä¸Šè§’
                cv2.putText(frame_bgr, txt, (30, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)
            else:
                # ç¬¬ä¸€å¸§é€Ÿåº¦æœªçŸ¥
                cv2.putText(frame_bgr, "x:? y:? z:?", (30, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)

        writer.write(frame_bgr)

    writer.release()
    print(f"è§†é¢‘å·²ä¿å­˜åˆ° {out_path} (åŒ…å«é€Ÿåº¦æ–¹å‘å¯è§†åŒ–)")

    cnt += 1
    if cnt > 10:    
        break